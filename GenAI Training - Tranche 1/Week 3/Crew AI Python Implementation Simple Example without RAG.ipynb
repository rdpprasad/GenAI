{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNygX0VZl36/0OxWvnkBFUs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Prepared by Tamal Acharya"],"metadata":{"id":"2qKtXulksXpx"}},{"cell_type":"markdown","source":["#Implementation using python and crewai without RAG and chunking"],"metadata":{"id":"oeOMz1Uf05m6"}},{"cell_type":"markdown","source":["#Define our agents\n","\n","##Agent Parameters used :\n","\n","1. Role : Defines the agent’s function within the crew. It determines the kind of tasks the agent is best suited for.\n","\n","2. Goal : The individual objective that the agent aims to achieve. It guides the agent’s decision-making process.\n","\n","3. Backstory :Provides context to the agent’s role and goal, enriching the interaction and collaboration dynamics.\n","\n","4. LLM (optional): Represents the language model that will run the agent. It dynamically fetches the model name from the OPENAI_MODEL_NAME environment variable, defaulting to \"gpt-4\" if not specified.\n","\n","5. Verbose (optional): Setting this to True configures the internal logger to provide detailed execution logs, aiding in debugging and monitoring. Default is False.\n","\n","6. Allow Delegation (optional): Agents can delegate tasks or questions to one another, ensuring that each task is handled by the most suitable agent. Default is True.\n","\n"],"metadata":{"id":"MRTmYt0fzHLS"}},{"cell_type":"code","source":["!pip install crewai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KT5rrUL60CGj","executionInfo":{"status":"ok","timestamp":1748515852459,"user_tz":0,"elapsed":52958,"user":{"displayName":"TAMAL ACHARYA","userId":"05985510221357911389"}},"outputId":"02a7b548-4215-4bae-ca69-c3f2ae0d24d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting crewai\n","  Downloading crewai-0.121.1-py3-none-any.whl.metadata (35 kB)\n","Collecting appdirs>=1.4.4 (from crewai)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Collecting auth0-python>=4.7.1 (from crewai)\n","  Downloading auth0_python-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n","Collecting chromadb>=0.5.23 (from crewai)\n","  Downloading chromadb-1.0.11-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.2.1)\n","Collecting instructor>=1.3.3 (from crewai)\n","  Downloading instructor-1.8.3-py3-none-any.whl.metadata (24 kB)\n","Collecting json-repair>=0.25.2 (from crewai)\n","  Downloading json_repair-0.46.0-py3-none-any.whl.metadata (12 kB)\n","Collecting json5>=0.10.0 (from crewai)\n","  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n","Collecting jsonref>=1.1.0 (from crewai)\n","  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n","Collecting litellm==1.68.0 (from crewai)\n","  Downloading litellm-1.68.0-py3-none-any.whl.metadata (36 kB)\n","Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.81.0)\n","Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n","Collecting opentelemetry-api>=1.30.0 (from crewai)\n","  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-sdk>=1.30.0 (from crewai)\n","  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n","Collecting pdfplumber>=0.11.4 (from crewai)\n","  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.11.4)\n","Collecting python-dotenv>=1.0.0 (from crewai)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting pyvis>=0.3.2 (from crewai)\n","  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n","Collecting tomli-w>=1.1.0 (from crewai)\n","  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n","Collecting tomli>=2.0.2 (from crewai)\n","  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Collecting uv>=0.4.25 (from crewai)\n","  Downloading uv-0.7.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (3.11.15)\n","Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (0.28.1)\n","Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (8.7.0)\n","Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (3.1.6)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (4.23.0)\n","Collecting openai>=1.13.3 (from crewai)\n","  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (0.9.0)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm==1.68.0->crewai) (0.21.1)\n","Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n","Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.10.1)\n","Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.32.3)\n","Requirement already satisfied: urllib3>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai) (2.4.0)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.2.2.post1)\n","Collecting fastapi==0.115.9 (from chromadb>=0.5.23->crewai)\n","  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n","Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (2.0.2)\n","Collecting posthog>=2.4.0 (from chromadb>=0.5.23->crewai)\n","  Downloading posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.13.2)\n","Collecting onnxruntime>=1.14.1 (from chromadb>=0.5.23->crewai)\n","  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.5.23->crewai)\n","  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n","Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.67.1)\n","Collecting overrides>=7.3.1 (from chromadb>=0.5.23->crewai)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.71.0)\n","Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n","  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.15.3)\n","Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n","  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (9.1.2)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.0.2)\n","Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n","  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.10.18)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n","Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb>=0.5.23->crewai)\n","  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n","Collecting jiter<0.9,>=0.6.1 (from instructor>=1.3.3->crewai)\n","  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.33.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.30.0->crewai)\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Collecting importlib-metadata>=6.8.0 (from litellm==1.68.0->crewai)\n","  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.70.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n","  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.33.1->opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (5.29.4)\n","Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk>=1.30.0->crewai)\n","  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting pdfminer.six==20250327 (from pdfplumber>=0.11.4->crewai)\n","  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (11.2.1)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n","  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber>=0.11.4->crewai) (3.4.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.4.1)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.1.0)\n","Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.68.0->crewai) (1.20.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (3.10)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (24.2)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (1.2.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.30.0->crewai) (1.17.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.68.0->crewai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.68.0->crewai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.68.0->crewai) (0.16.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.68.0->crewai) (3.21.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.2.0)\n","Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.19.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.68.0->crewai) (3.0.2)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.68.0->crewai) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.68.0->crewai) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.68.0->crewai) (0.25.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.38.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.2.2)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (25.2.10)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.13.1)\n","Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n","  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n","  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n","  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.5.23->crewai)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (3.0.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm==1.68.0->crewai) (0.31.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n","  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (15.0.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (4.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.68.0->crewai) (2025.3.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.6.1)\n","Downloading crewai-0.121.1-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading litellm-1.68.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Downloading auth0_python-4.9.0-py3-none-any.whl (135 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chromadb-1.0.11-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading instructor-1.8.3-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading json_repair-0.46.0-py3-none-any.whl (22 kB)\n","Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n","Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n","Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n","Downloading uv-0.7.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n","Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n","Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n","Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n","Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-4.2.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=0ffa1e13101566c56a532cb7544d89b79cfd096096af8b986ab04f1113b7c4ff\n","  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, appdirs, uvloop, uvicorn, uv, tomli-w, tomli, python-dotenv, pypdfium2, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, jsonref, json5, json-repair, jiter, jedi, importlib-metadata, humanfriendly, httptools, deprecated, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pyvis, pdfminer.six, opentelemetry-semantic-conventions, openai, onnxruntime, kubernetes, fastapi, auth0-python, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, litellm, instructor, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, crewai\n","  Attempting uninstall: jiter\n","    Found existing installation: jiter 0.10.0\n","    Uninstalling jiter-0.10.0:\n","      Successfully uninstalled jiter-0.10.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.7.0\n","    Uninstalling importlib_metadata-8.7.0:\n","      Successfully uninstalled importlib_metadata-8.7.0\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.81.0\n","    Uninstalling openai-1.81.0:\n","      Successfully uninstalled openai-1.81.0\n","Successfully installed appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.9.0 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.11 coloredlogs-15.0.1 crewai-0.121.1 deprecated-1.2.18 durationpy-0.10 fastapi-0.115.9 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 instructor-1.8.3 jedi-0.19.2 jiter-0.8.2 json-repair-0.46.0 json5-0.12.0 jsonref-1.1.0 kubernetes-32.0.1 litellm-1.68.0 mmh3-5.1.0 onnxruntime-1.22.0 openai-1.75.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-exporter-otlp-proto-http-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 overrides-7.7.0 pdfminer.six-20250327 pdfplumber-0.11.6 posthog-4.2.0 pypdfium2-4.30.1 pypika-0.48.9 python-dotenv-1.1.0 pyvis-0.3.2 starlette-0.45.3 tomli-2.2.1 tomli-w-1.2.0 uv-0.7.8 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["importlib_metadata"]},"id":"92eab6ab867d40f3ae87da91db9d3232"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install -qU langchain-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpmK7VIgmeh7","executionInfo":{"status":"ok","timestamp":1748516092571,"user_tz":0,"elapsed":8674,"user":{"displayName":"TAMAL ACHARYA","userId":"05985510221357911389"}},"outputId":"33808acc-956a-4654-95ed-3cf2c9c4028f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install langchain-openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0UxfbwSm6CQ","executionInfo":{"status":"ok","timestamp":1748516353239,"user_tz":0,"elapsed":3123,"user":{"displayName":"TAMAL ACHARYA","userId":"05985510221357911389"}},"outputId":"44bec390-7689-4f0b-b67a-7e65b094d325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.18)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.61 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.62)\n","Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.75.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n","Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.3.42)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (9.1.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (4.13.2)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.61->langchain-openai) (2.11.4)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.61->langchain-openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain-openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.61->langchain-openai) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n"]}]},{"cell_type":"code","source":["!pip install langchain_google_genai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"I9ziW0QZspdT","executionInfo":{"status":"ok","timestamp":1748516392924,"user_tz":0,"elapsed":5263,"user":{"displayName":"TAMAL ACHARYA","userId":"05985510221357911389"}},"outputId":"d74168f3-2848-4c72-ca62-b881cc00a9da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_google_genai\n","  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n","Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain_google_genai)\n","  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.62)\n","Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.4)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.24.2)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.4)\n","Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.3.42)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (9.1.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (6.0.2)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (4.13.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.23.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (4.9.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (0.16.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.4.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.62->langchain_google_genai) (1.3.1)\n","Downloading langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n","  Attempting uninstall: google-ai-generativelanguage\n","    Found existing installation: google-ai-generativelanguage 0.6.15\n","    Uninstalling google-ai-generativelanguage-0.6.15:\n","      Successfully uninstalled google-ai-generativelanguage-0.6.15\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain_google_genai-2.1.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"c1037a3c35e741ef8691b53f1c85ce07"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVMTjiKCy-WJ"},"outputs":[],"source":["from crewai import Agent, Task, Process, Crew\n","import os\n","from google.colab import userdata\n","from langchain_google_genai import ChatGoogleGenerativeAI # Import ChatGoogleGenerativeAI\n","\n","\n","GOOGLE_API_KEY = \"your_own_api_key\"\n","\n","# Configure environment and LLM - assuming you want to use Google GenAI here too\n","#os.environ[\"GOOGLE_API_KEY\"] = 'GOOGLE_API_KEY'\n","#llm = ChatGoogleGenerativeAI(model=\"gemini/gemini-1.5-flash\", temperature=0.3)\n","\n","from crewai import Agent, LLM\n","\n","llm = LLM(\n","    api_key= GOOGLE_API_KEY,\n","    model=\"gemini/gemini-1.5-flash\",\n",")\n","\n","# #Generate and setup the GROQ_API_KEY\n","# # Define the API key as a variable\n","# GROQ_API_KEY = \"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\"\n","# import os\n","# # Set the environment variable using the defined variable\n","# os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n","# from google.colab import userdata\n","# import os\n","# #os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n","\n","# #Setup the LLM\n","# from langchain_openai import ChatOpenAI\n","\n","# llm = ChatOpenAI(\n","#     openai_api_base=\"https://api.groq.com/openai/v1\",\n","#     openai_api_key=os.environ['GROQ_API_KEY'],\n","#     model_name=\"llama3-8b-8192\",\n","#     temperature=0,\n","#     max_tokens=1000,\n","# )\n","\n","# Define your agents with roles and goals\n","researcher = Agent(\n","    role='Senior Research Analyst',\n","    goal='Uncover groundbreaking insights in AI',\n","    backstory=\"\"\"You are a Senior Research Analyst at a leading tech think tank.\n","    Your expertise lies in identifying emerging trends and their potential impact.\n","    You have a knack for sifting through complex data and presenting actionable findings.\"\"\",\n","    verbose=True,\n","    allow_delegation=False,\n","    llm=llm # Explicitly set the LLM for the agent\n",")\n","writer = Agent(\n","    role='Tech Content Strategist',\n","    goal='Craft compelling content on AI advancements',\n","    backstory=\"\"\"You are a renowned Tech Content Strategist, known for your ability to explain complex technical concepts\n","    in an engaging and understandable manner. You transform raw data and insights into captivating narratives.\"\"\",\n","    verbose=True,\n","    allow_delegation=False,\n","    llm=llm # Explicitly set the LLM for the agent\n",")\n"]},{"cell_type":"markdown","source":["#Define Tasks for the agents\n","\n","##Task Parameters\n","\n","1. Description: A clear, concise statement of what the task entails.\n","\n","2. Agent: The agent responsible for the task, assigned either directly or by the crew’s process.\n","\n","3. Expected Output: A detailed description of what the task’s completion looks like.\n","\n","4. Tools (optional): The functions or capabilities the agent can utilize to perform the task\n","\n","5. Context (optional): Specifies tasks whose outputs are used as context for this task."],"metadata":{"id":"qX7ZSpPuzwlY"}},{"cell_type":"code","source":["# Create tasks for your agents\n","task1 = Task(\n","    description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI, focusing on\n","    Transformer models and their applications in natural language processing.\n","    Identify key trends, breakthrough research, and potential future directions.\n","    Your final output should be a detailed report on the latest AI breakthroughs.\"\"\",\n","    expected_output=\"A detailed report summarizing the latest AI breakthroughs, including key trends, breakthrough research, and potential future directions in Transformer models and NLP applications.\", # Added expected_output\n","    agent=researcher\n",")\n","\n","task2 = Task(\n","    description=\"\"\"Using the insights from the research report, develop a compelling blog post\n","    that highlights the most significant AI advancements for a tech-savvy audience.\n","    Your post should be informative, engaging, and easy to understand,\n","    explaining the impact of these advancements on the future of AI.\"\"\",\n","    expected_output=\"A compelling and informative blog post, written for a tech-savvy audience, explaining the most significant AI advancements based on the research report.\", # Added expected_output\n","    agent=writer\n",")"],"metadata":{"id":"YCnVkTzSzsrA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -qU langchain-google-genai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e_sZ3T2SyS_","executionInfo":{"status":"ok","timestamp":1748492832849,"user_tz":0,"elapsed":7767,"user":{"displayName":"TAMAL ACHARYA","userId":"05985510221357911389"}},"outputId":"c0dd1cc9-b0eb-4418-c82b-bb1222641ccc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.4 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/438.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.4/438.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# Instantiate your crew\n","crew = Crew(\n","    agents=[researcher, writer],\n","    tasks=[task1, task2],\n","    process=Process.sequential,  # Tasks will be executed in order\n","    verbose=False\n",")\n","\n","# Get your crew to work!\n","result = crew.kickoff()\n","\n","print(\"########################\")\n","result\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3D7ZSQcZzChH","executionInfo":{"status":"ok","timestamp":1748516645460,"user_tz":0,"elapsed":14403,"user":{"displayName":"TAMAL ACHARYA","userId":"05985510221357911389"}},"outputId":"04a71a72-3feb-457f-fd58-74e4341a72ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n","\u001b[95m## Task:\u001b[00m \u001b[92mConduct a comprehensive analysis of the latest advancements in AI, focusing on\n","    Transformer models and their applications in natural language processing.\n","    Identify key trends, breakthrough research, and potential future directions.\n","    Your final output should be a detailed report on the latest AI breakthroughs.\u001b[00m\n","\n","\n","\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n","\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n","**Executive Summary:**\n","\n","Transformer models have revolutionized Natural Language Processing (NLP), achieving state-of-the-art results in various tasks. This report analyzes recent advancements, focusing on key trends, breakthrough research, and future directions.  We explore improvements in model architecture (e.g., efficient Transformers, Mixture-of-Experts), training methodologies (e.g., reinforcement learning, curriculum learning), and applications (e.g., improved dialogue systems, advanced code generation).  The report concludes by highlighting potential challenges and opportunities, emphasizing the ethical considerations surrounding increasingly powerful NLP models.\n","\n","\n","**1. Key Trends in Transformer Models and NLP:**\n","\n","* **Increased Model Scale:**  The trend towards larger, more parameter-rich models continues.  Models with hundreds of billions or even trillions of parameters are demonstrating remarkable capabilities, albeit with increased computational costs.  Research is focusing on more efficient training and deployment strategies to mitigate this.\n","\n","* **Efficient Architectures:**  Addressing the computational burden of large models, research is actively developing more efficient Transformer architectures.  This includes techniques like sparse attention mechanisms (e.g., Longformer, Reformer), linear attention, and model quantization.\n","\n","* **Multi-Modality:**  Integrating Transformers with other modalities beyond text, such as images and audio, is gaining traction.  Multi-modal Transformers can process and understand information from different sources simultaneously, leading to more comprehensive and context-aware applications.\n","\n","* **Improved Training Techniques:**  Advances in training methodologies are crucial for better performance and efficiency.  Techniques like reinforcement learning from human feedback (RLHF) are enhancing model alignment with human preferences, while curriculum learning helps models learn more effectively by gradually increasing task complexity.\n","\n","* **Focus on Explainability and Interpretability:**  The \"black box\" nature of large language models is a growing concern.  Research efforts are dedicated to developing techniques to improve the explainability and interpretability of Transformer models, making them more transparent and trustworthy.\n","\n","\n","**2. Breakthrough Research:**\n","\n","* **Scaling Laws and Model Capacity:**  Recent research has empirically established scaling laws for Transformer models, providing insights into the relationship between model size, dataset size, and performance. This understanding guides the design of future, even more powerful models.\n","\n","* **Instruction Tuning and Reinforcement Learning from Human Feedback (RLHF):**  These techniques significantly improve the alignment of large language models with human intentions, leading to more helpful, harmless, and aligned responses.  Models trained with RLHF demonstrate improved performance in various tasks and exhibit better control over their output.\n","\n","* **Advances in Few-Shot and Zero-Shot Learning:**  Techniques like prompt engineering and meta-learning enable Transformers to perform well on new tasks with limited or no training data, expanding their applicability and reducing the need for extensive labeled datasets.\n","\n","* **Improved Code Generation Models:**  Transformer-based models have achieved impressive results in code generation, translation, and debugging.  This advancement has significant implications for software development, automation, and increased developer productivity.\n","\n","* **Development of Robust and Generalizable Models:**  Research is focusing on creating Transformer models that are more robust to noisy or adversarial inputs and generalize better to unseen data and tasks.  This requires addressing challenges like bias mitigation and improving out-of-distribution generalization.\n","\n","\n","**3. Potential Future Directions:**\n","\n","* **Personalized and Adaptive NLP:**  Future Transformers will likely adapt to individual user needs and preferences, providing personalized language processing experiences.\n","\n","* **Enhanced Human-Computer Interaction:**  More natural and intuitive interfaces enabled by sophisticated dialogue systems will transform how we interact with computers.\n","\n","* **Autonomous Systems and Robotics:**  Transformers can empower autonomous systems by enabling them to understand and interact with the world through natural language.\n","\n","* **Scientific Discovery and Knowledge Synthesis:**  Transformers can be instrumental in analyzing vast scientific datasets, accelerating scientific breakthroughs and promoting knowledge synthesis across various domains.\n","\n","* **Addressing Ethical Concerns:**  Ongoing research is essential to mitigate potential biases, ensure fairness, and prevent the misuse of powerful NLP models.  Developing mechanisms for responsible AI development and deployment is critical.\n","\n","\n","\n","**4. Challenges and Opportunities:**\n","\n","* **Computational Costs:**  Training and deploying extremely large models remain computationally expensive, requiring significant resources and infrastructure.\n","\n","* **Data Bias and Fairness:**  Transformer models are susceptible to biases present in the training data, leading to unfair or discriminatory outcomes.  Addressing this requires careful data curation and bias mitigation techniques.\n","\n","* **Explainability and Interpretability:**  Understanding how these complex models make decisions remains a significant challenge.  Improved methods for explaining model outputs are crucial for building trust and ensuring responsible use.\n","\n","* **Security and Safety:**  Large language models can be vulnerable to adversarial attacks and misuse.  Robust security measures are essential to prevent malicious exploitation.\n","\n","\n","**Conclusion:**\n","\n","Transformer models have driven remarkable progress in NLP, yielding transformative applications across various domains.  While significant challenges remain, ongoing research and development promise even more powerful and impactful NLP systems in the future.  Addressing ethical considerations and fostering responsible AI development will be critical in maximizing the benefits and minimizing the risks associated with these advancements.\u001b[00m\n","\n","\n","\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n","\u001b[95m## Task:\u001b[00m \u001b[92mUsing the insights from the research report, develop a compelling blog post\n","    that highlights the most significant AI advancements for a tech-savvy audience.\n","    Your post should be informative, engaging, and easy to understand,\n","    explaining the impact of these advancements on the future of AI.\u001b[00m\n","\n","\n","\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n","\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n","## Transformer Models: Reshaping the Landscape of NLP and the Future of AI\n","\n","The world of Natural Language Processing (NLP) has been fundamentally reshaped by the advent of Transformer models.  These powerful architectures have consistently shattered performance benchmarks across a wide range of tasks, pushing the boundaries of what's possible in AI.  But the revolution isn't over; ongoing advancements are paving the way for even more sophisticated and impactful applications.  This post delves into the key trends, breakthrough research, and future directions shaping the exciting trajectory of Transformer models.\n","\n","\n","**The Rise of the Giants (and How to Tame Them):**\n","\n","One undeniable trend is the relentless pursuit of scale.  Models boasting hundreds of billions, even trillions, of parameters are demonstrating capabilities previously deemed science fiction.  However, this comes at a significant computational cost.  The good news?  Research is vigorously tackling this challenge.  Efficient architectures like Longformer and Reformer, employing techniques such as sparse attention and linear attention, are significantly reducing the computational burden without sacrificing performance.  Model quantization, another promising avenue, further minimizes resource consumption.\n","\n","\n","**Beyond Words: The Multi-Modal Revolution:**\n","\n","The future of NLP isn't solely about text.  Multi-modal Transformers are emerging, capable of seamlessly integrating and interpreting information from various sources – text, images, and audio.  Imagine a system understanding a user's query accompanied by an image, providing far richer and more contextually relevant responses. This capability opens doors to a plethora of innovative applications, from advanced chatbots to sophisticated robotics.\n","\n","\n","**Training Smarter, Not Harder:**\n","\n","Improvements in training methodologies are equally crucial.  Reinforcement learning from human feedback (RLHF) is refining models to better align with human preferences, producing more helpful, harmless, and controlled outputs.  Curriculum learning, on the other hand, optimizes the learning process by gradually increasing task complexity, enhancing the model's overall efficiency and performance.\n","\n","\n","**Unlocking the Black Box: Explainability and Interpretability:**\n","\n","The \"black box\" nature of large language models has rightly raised concerns.  The field is actively pursuing techniques to enhance explainability and interpretability.  Understanding *why* a model makes a particular prediction is crucial for building trust, ensuring responsible use, and mitigating potential biases.\n","\n","\n","**Breakthrough Research: Shaping the Future:**\n","\n","Several recent breakthroughs underscore the rapid progress in the field:\n","\n","* **Scaling Laws:** Empirical research has established scaling laws, providing invaluable insights into the relationship between model size, data size, and performance. This understanding is guiding the development of future, even more powerful models.\n","* **Instruction Tuning and RLHF:** These techniques have dramatically improved the alignment of models with human intentions, yielding more helpful and reliable results.\n","* **Few-Shot and Zero-Shot Learning:**  Techniques like prompt engineering are enabling Transformers to perform well on new tasks with minimal or no training data, democratizing access to powerful NLP capabilities.\n","* **Code Generation:**  Transformers are revolutionizing software development, enabling automated code generation, translation, and debugging, boosting developer productivity significantly.\n","* **Robustness and Generalization:**  Researchers are actively focusing on creating models that are more resistant to noisy or adversarial inputs and generalize well to unseen data and tasks.\n","\n","\n","**The Future is Now (and What We Need to Do):**\n","\n","The future of Transformer models promises transformative advancements:\n","\n","* **Personalization:**  Tailored NLP experiences catering to individual needs and preferences.\n","* **Enhanced Human-Computer Interaction:**  More natural and intuitive interfaces powered by sophisticated dialogue systems.\n","* **Autonomous Systems:**  Empowering autonomous systems with natural language understanding and interaction capabilities.\n","* **Scientific Discovery:**  Accelerating scientific breakthroughs through the analysis of massive scientific datasets.\n","\n","However, this progress necessitates addressing crucial challenges:\n","\n","* **Computational Costs:**  The high computational demands of large models require innovative solutions for efficient training and deployment.\n","* **Data Bias and Fairness:**  Addressing biases present in training data is paramount to ensuring fair and equitable outcomes.\n","* **Explainability and Interpretability:**  Continued research is needed to make these models more transparent and understandable.\n","* **Security and Safety:**  Robust security measures are essential to prevent malicious use and exploitation.\n","\n","\n","**Conclusion:**\n","\n","Transformer models have undeniably revolutionized NLP. While substantial challenges remain, the ongoing research and development efforts promise even more powerful and impactful systems.  By addressing ethical considerations and prioritizing responsible AI development, we can harness the incredible potential of Transformer models for the benefit of all.  The future of AI is being written, one Transformer at a time.\u001b[00m\n","\n","\n","########################\n"]},{"output_type":"execute_result","data":{"text/plain":["CrewOutput(raw='## Transformer Models: Reshaping the Landscape of NLP and the Future of AI\\n\\nThe world of Natural Language Processing (NLP) has been fundamentally reshaped by the advent of Transformer models.  These powerful architectures have consistently shattered performance benchmarks across a wide range of tasks, pushing the boundaries of what\\'s possible in AI.  But the revolution isn\\'t over; ongoing advancements are paving the way for even more sophisticated and impactful applications.  This post delves into the key trends, breakthrough research, and future directions shaping the exciting trajectory of Transformer models.\\n\\n\\n**The Rise of the Giants (and How to Tame Them):**\\n\\nOne undeniable trend is the relentless pursuit of scale.  Models boasting hundreds of billions, even trillions, of parameters are demonstrating capabilities previously deemed science fiction.  However, this comes at a significant computational cost.  The good news?  Research is vigorously tackling this challenge.  Efficient architectures like Longformer and Reformer, employing techniques such as sparse attention and linear attention, are significantly reducing the computational burden without sacrificing performance.  Model quantization, another promising avenue, further minimizes resource consumption.\\n\\n\\n**Beyond Words: The Multi-Modal Revolution:**\\n\\nThe future of NLP isn\\'t solely about text.  Multi-modal Transformers are emerging, capable of seamlessly integrating and interpreting information from various sources – text, images, and audio.  Imagine a system understanding a user\\'s query accompanied by an image, providing far richer and more contextually relevant responses. This capability opens doors to a plethora of innovative applications, from advanced chatbots to sophisticated robotics.\\n\\n\\n**Training Smarter, Not Harder:**\\n\\nImprovements in training methodologies are equally crucial.  Reinforcement learning from human feedback (RLHF) is refining models to better align with human preferences, producing more helpful, harmless, and controlled outputs.  Curriculum learning, on the other hand, optimizes the learning process by gradually increasing task complexity, enhancing the model\\'s overall efficiency and performance.\\n\\n\\n**Unlocking the Black Box: Explainability and Interpretability:**\\n\\nThe \"black box\" nature of large language models has rightly raised concerns.  The field is actively pursuing techniques to enhance explainability and interpretability.  Understanding *why* a model makes a particular prediction is crucial for building trust, ensuring responsible use, and mitigating potential biases.\\n\\n\\n**Breakthrough Research: Shaping the Future:**\\n\\nSeveral recent breakthroughs underscore the rapid progress in the field:\\n\\n* **Scaling Laws:** Empirical research has established scaling laws, providing invaluable insights into the relationship between model size, data size, and performance. This understanding is guiding the development of future, even more powerful models.\\n* **Instruction Tuning and RLHF:** These techniques have dramatically improved the alignment of models with human intentions, yielding more helpful and reliable results.\\n* **Few-Shot and Zero-Shot Learning:**  Techniques like prompt engineering are enabling Transformers to perform well on new tasks with minimal or no training data, democratizing access to powerful NLP capabilities.\\n* **Code Generation:**  Transformers are revolutionizing software development, enabling automated code generation, translation, and debugging, boosting developer productivity significantly.\\n* **Robustness and Generalization:**  Researchers are actively focusing on creating models that are more resistant to noisy or adversarial inputs and generalize well to unseen data and tasks.\\n\\n\\n**The Future is Now (and What We Need to Do):**\\n\\nThe future of Transformer models promises transformative advancements:\\n\\n* **Personalization:**  Tailored NLP experiences catering to individual needs and preferences.\\n* **Enhanced Human-Computer Interaction:**  More natural and intuitive interfaces powered by sophisticated dialogue systems.\\n* **Autonomous Systems:**  Empowering autonomous systems with natural language understanding and interaction capabilities.\\n* **Scientific Discovery:**  Accelerating scientific breakthroughs through the analysis of massive scientific datasets.\\n\\nHowever, this progress necessitates addressing crucial challenges:\\n\\n* **Computational Costs:**  The high computational demands of large models require innovative solutions for efficient training and deployment.\\n* **Data Bias and Fairness:**  Addressing biases present in training data is paramount to ensuring fair and equitable outcomes.\\n* **Explainability and Interpretability:**  Continued research is needed to make these models more transparent and understandable.\\n* **Security and Safety:**  Robust security measures are essential to prevent malicious use and exploitation.\\n\\n\\n**Conclusion:**\\n\\nTransformer models have undeniably revolutionized NLP. While substantial challenges remain, the ongoing research and development efforts promise even more powerful and impactful systems.  By addressing ethical considerations and prioritizing responsible AI development, we can harness the incredible potential of Transformer models for the benefit of all.  The future of AI is being written, one Transformer at a time.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Conduct a comprehensive analysis of the latest advancements in AI, focusing on\\n    Transformer models and their applications in natural language processing.\\n    Identify key trends, breakthrough research, and potential future directions.\\n    Your final output should be a detailed report on the latest AI breakthroughs.', name=None, expected_output='A detailed report summarizing the latest AI breakthroughs, including key trends, breakthrough research, and potential future directions in Transformer models and NLP applications.', summary='Conduct a comprehensive analysis of the latest advancements in AI,...', raw='**Executive Summary:**\\n\\nTransformer models have revolutionized Natural Language Processing (NLP), achieving state-of-the-art results in various tasks. This report analyzes recent advancements, focusing on key trends, breakthrough research, and future directions.  We explore improvements in model architecture (e.g., efficient Transformers, Mixture-of-Experts), training methodologies (e.g., reinforcement learning, curriculum learning), and applications (e.g., improved dialogue systems, advanced code generation).  The report concludes by highlighting potential challenges and opportunities, emphasizing the ethical considerations surrounding increasingly powerful NLP models.\\n\\n\\n**1. Key Trends in Transformer Models and NLP:**\\n\\n* **Increased Model Scale:**  The trend towards larger, more parameter-rich models continues.  Models with hundreds of billions or even trillions of parameters are demonstrating remarkable capabilities, albeit with increased computational costs.  Research is focusing on more efficient training and deployment strategies to mitigate this.\\n\\n* **Efficient Architectures:**  Addressing the computational burden of large models, research is actively developing more efficient Transformer architectures.  This includes techniques like sparse attention mechanisms (e.g., Longformer, Reformer), linear attention, and model quantization.\\n\\n* **Multi-Modality:**  Integrating Transformers with other modalities beyond text, such as images and audio, is gaining traction.  Multi-modal Transformers can process and understand information from different sources simultaneously, leading to more comprehensive and context-aware applications.\\n\\n* **Improved Training Techniques:**  Advances in training methodologies are crucial for better performance and efficiency.  Techniques like reinforcement learning from human feedback (RLHF) are enhancing model alignment with human preferences, while curriculum learning helps models learn more effectively by gradually increasing task complexity.\\n\\n* **Focus on Explainability and Interpretability:**  The \"black box\" nature of large language models is a growing concern.  Research efforts are dedicated to developing techniques to improve the explainability and interpretability of Transformer models, making them more transparent and trustworthy.\\n\\n\\n**2. Breakthrough Research:**\\n\\n* **Scaling Laws and Model Capacity:**  Recent research has empirically established scaling laws for Transformer models, providing insights into the relationship between model size, dataset size, and performance. This understanding guides the design of future, even more powerful models.\\n\\n* **Instruction Tuning and Reinforcement Learning from Human Feedback (RLHF):**  These techniques significantly improve the alignment of large language models with human intentions, leading to more helpful, harmless, and aligned responses.  Models trained with RLHF demonstrate improved performance in various tasks and exhibit better control over their output.\\n\\n* **Advances in Few-Shot and Zero-Shot Learning:**  Techniques like prompt engineering and meta-learning enable Transformers to perform well on new tasks with limited or no training data, expanding their applicability and reducing the need for extensive labeled datasets.\\n\\n* **Improved Code Generation Models:**  Transformer-based models have achieved impressive results in code generation, translation, and debugging.  This advancement has significant implications for software development, automation, and increased developer productivity.\\n\\n* **Development of Robust and Generalizable Models:**  Research is focusing on creating Transformer models that are more robust to noisy or adversarial inputs and generalize better to unseen data and tasks.  This requires addressing challenges like bias mitigation and improving out-of-distribution generalization.\\n\\n\\n**3. Potential Future Directions:**\\n\\n* **Personalized and Adaptive NLP:**  Future Transformers will likely adapt to individual user needs and preferences, providing personalized language processing experiences.\\n\\n* **Enhanced Human-Computer Interaction:**  More natural and intuitive interfaces enabled by sophisticated dialogue systems will transform how we interact with computers.\\n\\n* **Autonomous Systems and Robotics:**  Transformers can empower autonomous systems by enabling them to understand and interact with the world through natural language.\\n\\n* **Scientific Discovery and Knowledge Synthesis:**  Transformers can be instrumental in analyzing vast scientific datasets, accelerating scientific breakthroughs and promoting knowledge synthesis across various domains.\\n\\n* **Addressing Ethical Concerns:**  Ongoing research is essential to mitigate potential biases, ensure fairness, and prevent the misuse of powerful NLP models.  Developing mechanisms for responsible AI development and deployment is critical.\\n\\n\\n\\n**4. Challenges and Opportunities:**\\n\\n* **Computational Costs:**  Training and deploying extremely large models remain computationally expensive, requiring significant resources and infrastructure.\\n\\n* **Data Bias and Fairness:**  Transformer models are susceptible to biases present in the training data, leading to unfair or discriminatory outcomes.  Addressing this requires careful data curation and bias mitigation techniques.\\n\\n* **Explainability and Interpretability:**  Understanding how these complex models make decisions remains a significant challenge.  Improved methods for explaining model outputs are crucial for building trust and ensuring responsible use.\\n\\n* **Security and Safety:**  Large language models can be vulnerable to adversarial attacks and misuse.  Robust security measures are essential to prevent malicious exploitation.\\n\\n\\n**Conclusion:**\\n\\nTransformer models have driven remarkable progress in NLP, yielding transformative applications across various domains.  While significant challenges remain, ongoing research and development promise even more powerful and impactful NLP systems in the future.  Addressing ethical considerations and fostering responsible AI development will be critical in maximizing the benefits and minimizing the risks associated with these advancements.', pydantic=None, json_dict=None, agent='Senior Research Analyst', output_format=<OutputFormat.RAW: 'raw'>), TaskOutput(description='Using the insights from the research report, develop a compelling blog post\\n    that highlights the most significant AI advancements for a tech-savvy audience.\\n    Your post should be informative, engaging, and easy to understand,\\n    explaining the impact of these advancements on the future of AI.', name=None, expected_output='A compelling and informative blog post, written for a tech-savvy audience, explaining the most significant AI advancements based on the research report.', summary='Using the insights from the research report, develop a compelling...', raw='## Transformer Models: Reshaping the Landscape of NLP and the Future of AI\\n\\nThe world of Natural Language Processing (NLP) has been fundamentally reshaped by the advent of Transformer models.  These powerful architectures have consistently shattered performance benchmarks across a wide range of tasks, pushing the boundaries of what\\'s possible in AI.  But the revolution isn\\'t over; ongoing advancements are paving the way for even more sophisticated and impactful applications.  This post delves into the key trends, breakthrough research, and future directions shaping the exciting trajectory of Transformer models.\\n\\n\\n**The Rise of the Giants (and How to Tame Them):**\\n\\nOne undeniable trend is the relentless pursuit of scale.  Models boasting hundreds of billions, even trillions, of parameters are demonstrating capabilities previously deemed science fiction.  However, this comes at a significant computational cost.  The good news?  Research is vigorously tackling this challenge.  Efficient architectures like Longformer and Reformer, employing techniques such as sparse attention and linear attention, are significantly reducing the computational burden without sacrificing performance.  Model quantization, another promising avenue, further minimizes resource consumption.\\n\\n\\n**Beyond Words: The Multi-Modal Revolution:**\\n\\nThe future of NLP isn\\'t solely about text.  Multi-modal Transformers are emerging, capable of seamlessly integrating and interpreting information from various sources – text, images, and audio.  Imagine a system understanding a user\\'s query accompanied by an image, providing far richer and more contextually relevant responses. This capability opens doors to a plethora of innovative applications, from advanced chatbots to sophisticated robotics.\\n\\n\\n**Training Smarter, Not Harder:**\\n\\nImprovements in training methodologies are equally crucial.  Reinforcement learning from human feedback (RLHF) is refining models to better align with human preferences, producing more helpful, harmless, and controlled outputs.  Curriculum learning, on the other hand, optimizes the learning process by gradually increasing task complexity, enhancing the model\\'s overall efficiency and performance.\\n\\n\\n**Unlocking the Black Box: Explainability and Interpretability:**\\n\\nThe \"black box\" nature of large language models has rightly raised concerns.  The field is actively pursuing techniques to enhance explainability and interpretability.  Understanding *why* a model makes a particular prediction is crucial for building trust, ensuring responsible use, and mitigating potential biases.\\n\\n\\n**Breakthrough Research: Shaping the Future:**\\n\\nSeveral recent breakthroughs underscore the rapid progress in the field:\\n\\n* **Scaling Laws:** Empirical research has established scaling laws, providing invaluable insights into the relationship between model size, data size, and performance. This understanding is guiding the development of future, even more powerful models.\\n* **Instruction Tuning and RLHF:** These techniques have dramatically improved the alignment of models with human intentions, yielding more helpful and reliable results.\\n* **Few-Shot and Zero-Shot Learning:**  Techniques like prompt engineering are enabling Transformers to perform well on new tasks with minimal or no training data, democratizing access to powerful NLP capabilities.\\n* **Code Generation:**  Transformers are revolutionizing software development, enabling automated code generation, translation, and debugging, boosting developer productivity significantly.\\n* **Robustness and Generalization:**  Researchers are actively focusing on creating models that are more resistant to noisy or adversarial inputs and generalize well to unseen data and tasks.\\n\\n\\n**The Future is Now (and What We Need to Do):**\\n\\nThe future of Transformer models promises transformative advancements:\\n\\n* **Personalization:**  Tailored NLP experiences catering to individual needs and preferences.\\n* **Enhanced Human-Computer Interaction:**  More natural and intuitive interfaces powered by sophisticated dialogue systems.\\n* **Autonomous Systems:**  Empowering autonomous systems with natural language understanding and interaction capabilities.\\n* **Scientific Discovery:**  Accelerating scientific breakthroughs through the analysis of massive scientific datasets.\\n\\nHowever, this progress necessitates addressing crucial challenges:\\n\\n* **Computational Costs:**  The high computational demands of large models require innovative solutions for efficient training and deployment.\\n* **Data Bias and Fairness:**  Addressing biases present in training data is paramount to ensuring fair and equitable outcomes.\\n* **Explainability and Interpretability:**  Continued research is needed to make these models more transparent and understandable.\\n* **Security and Safety:**  Robust security measures are essential to prevent malicious use and exploitation.\\n\\n\\n**Conclusion:**\\n\\nTransformer models have undeniably revolutionized NLP. While substantial challenges remain, the ongoing research and development efforts promise even more powerful and impactful systems.  By addressing ethical considerations and prioritizing responsible AI development, we can harness the incredible potential of Transformer models for the benefit of all.  The future of AI is being written, one Transformer at a time.', pydantic=None, json_dict=None, agent='Tech Content Strategist', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=3596, prompt_tokens=1588, cached_prompt_tokens=0, completion_tokens=2008, successful_requests=2))"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Of0MTEfl0na8"}},{"cell_type":"code","source":[],"metadata":{"id":"KPriDUJAx4sx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["BadRequestError: litellm.BadRequestError: LLM Provider NOT provided\n","\n","The error occurs because of how you set your LLM. Using the CrewAI LLM class, which uses LiteLLM in the background, you also need to provide the LLM provider.\n","\n","\n","For example, if you use the Anthropic Claude 3.5 Sonnet LLM, you need to put anthropic/ before setting the LLM.\n","\n","\n","from crewai import Agent, LLM\n","\n","my_llm = LLM(\n","\n","    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n","    model=\"anthropic/claude-3-5-sonnet-20240620\",\n",")\n","\n","my_agent = Agent(\n","\n","    ...,\n","    llm=my_llm,\n",")\n","\n","ERROR: LiteLLM call failed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=model='models/gemini-1.5-flash' google_api_key=SecretStr('**********') temperature=0.5 client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000179649639D0> default_metadata=() Pass model as E.g. For 'Huggingface' inference endpoints pass in completion(model='huggingface/starcoder',..) Learn more: https://docs.litellm.ai/docs/providers\n","\n","If you encounter this error, follow these two steps:\n","\n","Use the CrewAI LLM class, which leverages LiteLLM in the background.\n","Make sure to set the LLM provider before configuring the LLM.\n","For Google AI Studio, use gemini/<LLM name>.\n","\n","from crewai import Agent, LLM\n","\n","\n","my_llm = LLM(\n","\n","    api_key=os.getenv(\"GEMINI_API_KEY\"),\n","    model=\"gemini/gemini-1.5-flash\",\n","),\n","\n","my_agent = Agent(\n","\n","    ...,\n","    llm=my_llm,\n",")\n","\n","\n","Here are all the major LLM providers, as of today:\n","\n","\n","1. OpenAI: <LLM name> (Note: You don't have to set the LLM provider.)\n","\n","2. Azure OpenAI: azure/<your deployment name>\n","\n","3. Azure AI Studio: azure_ai/<LLM name>\n","\n","4. Anthropic: anthropic/<LLM name>\n","\n","5. Mistral API: mistral/<LLM name>\n","\n","6. Codestral API: codestral/<LLM name>\n","\n","7. Hugging Face: huggingface/<LLM name>\n","\n","8. Ollama: ollama/<LLM name>\n","\n","9. Groq: groq/<LLM name>\n","\n","10. Vertex AI: vertex_ai/<LLM name>\n","\n","11. Gemini Google AI Studio: gemini/<LLM name>\n","\n","12. AWS Sagemaker: sagemaker/<your endpoint name>\n","\n","13. AWS Bedrock: bedrock/<LLM name>\n","\n","14. Cohere: cohere/<LLM name>\n","\n","15. Anyscale: anyscale/<LLM name>\n","\n","16. Databricks: databricks/<LLM name>\n","\n","17. Together AI: together_ai/<LLM provider>/<LLM name>\n","\n","18. Replicate: replicate/<LLM name>\n","\n","19. Fireworks AI: fireworks_ai/<LLM name>\n","\n","20. Predibase: predibase/<LLM name>\n","\n","21. Nvidia NIM: nvidia_nim/<LLM provider>/<LLM name>\n","\n","22. IBM watsonx.ai: watsonx/<LLM provider>/<LLM name>\n","\n","23. LiteLLM Proxy (LLM Gateway): litellm_proxy/<LLM name>\n","\n","In case of an error or if you want to see the full list, please refer to the LiteLLM Providers page. https://docs.litellm.ai/docs/providers"],"metadata":{"id":"9t3lmQjGuT2g"}},{"cell_type":"code","source":[],"metadata":{"id":"hRsiKdD74Tsr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t5pSwgMu4ycv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RNV2q4Om5Ap3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IcbWTbuy5G24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EOb17l6m0mtv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Hj1xWriy0YIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3da8AFUM0mX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ui2SX25nl0WG"},"execution_count":null,"outputs":[]}]}